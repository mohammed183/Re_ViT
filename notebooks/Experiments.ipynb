{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb7a4fa-a9d9-4265-bf78-bd783a056859",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "In this section, we will attempt to verify the qualitative and quantitative aspects of each claim. We will indicate which claims cannot be verified due to the lack of the material published by the authors. We will mainly use pretrained models published to verify these claims. Below is a table with all the models mentioned in the paper and which versions of it are publicly available.\n",
    "\n",
    "|     Model      | Pretrained ImageNet | pretrained ImageNet-21 | Pretrained JFT |\n",
    "|:-------------:|:------------------:|:---------------------:|:-------------:|\n",
    "|   ResNet50x1   |         Yes         |          Yes           |       No       |\n",
    "|   ResNet50x2   |         No          |           No           |       No       |\n",
    "|  ResNet101x1   |         Yes         |          Yes           |       No       |\n",
    "|  ResNet152x1   |         No          |           No           |       No       |\n",
    "|  ResNet152x2   |         Yes         |          Yes           |       No       |\n",
    "|  ResNet152x4   |         Yes         |          Yes           |       No       |\n",
    "|  ResNet200x3   |         No          |           No           |       No       |\n",
    "|    ViT-B/32    |      Yes (SAM)      |          Yes           |       No       |\n",
    "|    ViT-B/16    |      Yes (SAM)      |          Yes           |       No       |\n",
    "|    ViT-L/32    |      Yes (SAM)      |          Yes           |       No       |\n",
    "|    ViT-L/16    |      Yes (SAM)      |          Yes           |       No       |\n",
    "|    ViT-H/14    |         No          |          Yes           |       No       |\n",
    "| R50x1+ViT-B/32 |         No          | No (but R26 available) |       No       |\n",
    "| R50x1+ViT-B/16 |         No          |          Yes           |       No       |\n",
    "| R50x1+ViT-L/32 |         No          |          Yes           |       No       |\n",
    "| R50x1+ViT-L/16 |         No          |          Yes           |       No       |\n",
    "\n",
    "Our task will be to try to reproduce all the qualitative claims, as well as any possible quantitative claims using the pretrained models presented in the previous table.\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91a6e2-1d94-4813-a27d-f4f4a0ac1c4f",
   "metadata": {},
   "source": [
    "## Experiment 1:\n",
    "\n",
    "In this experiment we want to reproduce the claim: “Vision Transformer outperforms state of the art CNNs on various classification tasks after pretraining on large datasets” by using the only available pretrained model in the table in that claim and compare it to the other model that are pretrained on the **ImageNet-21k** unlike in the original paper where the other models were trained on the **JFT-300M** private dataset.\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56201dbe-f1a2-475e-bb2c-4999c3a252a8",
   "metadata": {},
   "source": [
    "This Experiment is split into two notebooks:\n",
    "\n",
    "-   First notebook has the baseline model which is the [ResNet-152x4 model](ResNet.ipynb).\n",
    "-   We then have [Vit-L/16 model](ViT.ipynb) which we will fine tune.\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d0203-1f8d-41b0-9a1d-659516618437",
   "metadata": {},
   "source": [
    "After training both notebooks, now we can create the following table using the results stored in `resnet.json` and `vit.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8441a8-b5bd-4798-bf9b-c2ed2067bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the data from both json files and create a table with results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
