{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "In this section, we will attempt to verify the qualitative and quantitative aspects of each claim. We will indicate which claims cannot be verified due to the lack of the material published by the authors. We will mainly use pretrained models published to verify these claims. Below is a table with all the models mentioned in the paper and which versions of it are publicly available.\n",
    "\n",
    "|     Model      | Pretrained ImageNet | pretrained ImageNet-21 | Pretrained JFT |\n",
    "|:-------------:|:------------------:|:---------------------:|:-------------:|\n",
    "|   ResNet50x1   |         Yes         |          Yes           |       No       |\n",
    "|   ResNet50x2   |         No          |           No           |       No       |\n",
    "|  ResNet101x1   |         Yes         |          Yes           |       No       |\n",
    "|  ResNet152x1   |         No          |           No           |       No       |\n",
    "|  ResNet152x2   |         Yes         |          Yes           |       No       |\n",
    "|  ResNet152x4   |         Yes         |          Yes           |       No       |\n",
    "|  ResNet200x3   |         No          |           No           |       No       |\n",
    "|    ViT-B/32    |      Yes (SAM)      |          Yes           |       No       |\n",
    "|    ViT-B/16    |      Yes (SAM)      |          Yes           |       No       |\n",
    "|    ViT-L/32    |      Yes (SAM)      |          Yes           |       No       |\n",
    "|    ViT-L/16    |      Yes (SAM)      |          Yes           |       No       |\n",
    "|    ViT-H/14    |         No          |          Yes           |       No       |\n",
    "| R50x1+ViT-B/32 |         No          | No (but R26 available) |       No       |\n",
    "| R50x1+ViT-B/16 |         No          |          Yes           |       No       |\n",
    "| R50x1+ViT-L/32 |         No          |          Yes           |       No       |\n",
    "| R50x1+ViT-L/16 |         No          |          Yes           |       No       |\n",
    "\n",
    "Our task will be to try to reproduce all the qualitative claims, as well as any possible quantitative claims using the pretrained models presented in the previous table.\n",
    "\n",
    "------------------------------------------------------------------------"
   ],
   "id": "e1740d28-26a2-49fc-9a6b-745b296881ff"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1:\n",
    "\n",
    "In this experiment we want to reproduce the claim: “Vision Transformer outperforms state of the art CNNs on various classification tasks after pretraining on large datasets” by using the only available pretrained model in the table in that claim and compare it to the other model that are pretrained on the ImageNet-21k unlike in the original paper where the other models were trained on the JFT-300M private dataset.\n",
    "\n",
    "------------------------------------------------------------------------"
   ],
   "id": "a438a2e7-f757-435f-b824-7498745f07b6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this experiment we should be able to fill the following table and then we validate the claim:\n",
    "\n",
    "------------------------------------------------------------------------"
   ],
   "id": "d0990ba8-fa72-4dd2-8dbd-21cadec88a01"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Experiment is split into two notebooks:\n",
    "\n",
    "-   The first notebook we train the baseline ResNet-152x4 model (Here will be link to notebook)\n",
    "-   The second notebook we train the Vit-L/16 model (Here will be link to notebook) \\*\\*\\*"
   ],
   "id": "24935d2a-44b1-4223-a17d-c590a0b150fe"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
